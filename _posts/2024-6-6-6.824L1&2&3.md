---
layout: post
title: 2021L1、2、3
tags: MIT6.824
excerpt: 听课笔记，有部分补充内容；不是完全记录课程内容，单纯自己的记录；
---

# 2021 L1
<h2>主题</h2>
<p>&emsp;&emsp;在分布式系统设计中，需要考虑多个关键方面，以确保系统的可靠性、高性能和一致性。这些方面包括：</p>

<ol>
    <li>容错
        <p>容错机制分为可用性和可恢复性两个方面：</p>
        <ol>
            <li><strong>可用性</strong>：系统在部分节点故障时仍能继续提供服务;</li>
            <li><strong>可恢复性</strong>：系统能够从故障中恢复，重新运行任务并尽可能减少数据丢失;</li>
        </ol>
    </li>
    <li>一致性
        <p>在分布式系统中，多个副本的数据要保持一致;</p>
    </li>
    <li>高性能
        <p>高性能通常包括两个方面：吞吐量和低延迟;</p>
    </li>
    <li>实现部分
        <ol>
            <li><strong>管理并发性</strong>:
                <ol>
                    <li>锁和同步机制：确保多个进程或线程在访问共享资源时不会相互干扰;</li>
                    <li>事务：通过事务管理来保证多个操作的原子性和一致性;</li>
                </ol>
            </li>
            <li><strong>实现RPC</strong>（远程过程调用）:
                <p>用于不同节点之间的通信，需要考虑：</p>
                <ul>
                    <li>序列化和反序列化：将数据转换为可以通过网络传输的格式，并在接收端还原;</li>
                    <li>网络通信：使用底层协议（如HTTP、TCP）进行数据传输;</li>
                    <li>错误处理：处理网络故障、超时等异常情况;</li>
                </ul>
            </li>
        </ol>
    </li>
</ol>

<h2>错误处理 (MapReduce)</h2>
<p>&emsp;&emsp;当唯一的协调器（<code>master</code>）宕机时，需要重新运行整个任务;</p>

<p>&emsp;&emsp;也可以通过备份协调器或重新选举新的协调器（多个协调器）来继续任务;</p>

<p>&emsp;&emsp;遇到慢节点时，协调器会将属于慢节点的任务重新分配（复制）给第一个（按照完成任务的快慢顺序）完成任务的<code>worker</code>：通过动态调整任务分配，减少因慢节点导致的整体延迟;</p>

<h2>Combiner Function</h2>
<p>&emsp;&emsp;<code>Combiner Function</code>是一个可选的优化手段，当<code>Map</code>函数处理后有大量重复值时，用户可以指定一个<code>Combiner</code>函数，在本地先合并这些重复值，再写入中间文件，最后发送出去；这样可以减少网络传输的数据量，提高整体性能。</p>

<br>

# 2021 L2
<a href="https://acceleratorssr.github.io/2024/06/19/GC">go的垃圾回收机制</a>

使用线程所遇到的挑战
1. 线程的竞态条件，解决方法：
● 通过避免使用共享内存，而是使用channel；
● 使用锁；
1. 协调
● 使用channel或者条件变量
1. 死锁

<br>

# 2021 L3
<p><strong>"Building ft storage"</strong>指构建分布式系统中的 fault-tolerant（FT）存储。在分布式系统中，FT存储是指能够在组件或节点发生故障时保持系统可用性和数据一致性的存储系统，这意味着系统能够在硬件故障或网络分区等问题下继续运行，并且不会丢失数据或使数据不一致；</p>
<p>难点：需要高性能 -> 需要跨服务器对数据分片 -> 数千台服务器可能个别出现宕机（换句话说持续会发生错误） -> 需要容错性 -> 复制多份数据 -> 可能导致数据一致性的问题 -> 需要持久性的协议（影响系统容量和分片数设计</p>
<p>并发问题 错误问题</p>

<h4>GFS</h4>
<p>关键属性：</p>
<ul>
  <li>大：大规模数据集；</li>
  <li>快速：自动分片到多个磁盘，支持并发读；</li>
  <li>全局的：共享的，即应用程序看到的都是同一个文件系统；</li>
  <li>容错：自动恢复；</li>
</ul>
<p><strong>master：</strong></p>
<ul>
  <li><strong>文件名到块句柄数组的映射关系</strong>，维护在内存中，需要持久化保存；</li>
  <li>块句柄中有<strong>版本号</strong>（持久存储）和<strong>块服务（chunkserver）列表</strong>（内有块的复制），主/次要副本，释放时间；</li>
</ul>
<blockquote>
<p><strong>主要副本：</strong></p>
<ul>
  <li>负责协调对应数据块的所有读取和写入操作，包括客户端的读取请求和写入请求，检查租约等；</li>
  <li>通过协调所有操作，确保所有副本之间的数据一致性，即使在面对网络延迟或节点故障时也能保持数据的一致性；</li>
</ul>
<p><strong>版本号：</strong></p>
<ul>
  <li>GFS 中的每个数据块都有一个关联的版本号，用于标识该数据块的当前版本，当数据块被修改时，其版本号会增加，以反映出数据的变化；</li>
</ul>
</blockquote>
<p><strong>日志</strong>（存入持久存储中：名称空间发生更改、在GFS创建新文件、改变文件映射块句柄的关系） + <strong>检查点</strong>（同样存入持久存储中，是系统周期性地创建的一种快照，记录了系统的状态，以便在需要时快速恢复）；</p>
<p>&emsp;&emsp;<strong>写入持久存储后才会响应client</strong>；</p>
<p><strong>租约：</strong>Lease，是一种用于协调并发访问的机制，它允许客户端对数据块进行独占式的访问，并<strong>防止多个客户端同时对同一数据块进行写操作</strong>；</p>

<p><strong>租约流程</strong></p>
<ul>
  <li>当客户端需要对数据块进行写操作时，它首先向 Master 请求获取该数据块的租约。</li>
  <li>Master 接收到租约请求后，会将租约授予请求的客户端，并设置一个租约超时时间（Lease Timeout）。在租约超时之前，该客户端可以独占地对数据块进行写操作。</li>
  <li>在租约的有效期内，其他客户端仍然可以读取数据块，但不能进行写操作。如果其他客户端也需要对同一数据块进行写操作，它们必须等待租约过期或者租约被释放后才能获取租约并执行写操作。</li>
  <li>客户端在完成对数据块的写操作后，可以选择将租约释放或者续租（Renew Lease）。如果客户端选择续租，它需要向 Master 发送租约续租请求，以延长租约的有效期。</li>
</ul>

<p><strong>client Reading：</strong></p>
<ul>
  <li>发送请求到 master；</li>
  <li>master 响应 chunkhandle + 块服务列表 + 版本号；</li>
  <li>缓存这个list；</li>
  <li>从最近的chunkserver读取；</li>
  <li>chunkserver检查版本号（避免读取到过时的数据），通过则返回数据；</li>
</ul>

<p><strong>client Writing：append</strong></p>
<ul>
  <li>发送请求，master查找文件名和块句柄映射后，通过块句柄查找块服务列表；即Master 接收到写入请求后，会确定主要副本，增加版本号（仅master维护），并向客户端返回相应的租约信息以及主要副本的位置信息；如果数据块的主要副本还不存在（第一次写入），Master 会选择一些数据节点作为该数据块的副本节点，并告知这些节点它们将是该数据块的次要副本；</li>
  <li>客户端收到租约信息和主要副本的位置信息后，直接与距离最近的副本建立连接，并将需要写入的数据块发送给这个副本；数据流会以流水线的方式在精心挑选的 chunkserver 链（最近的副本节点）之间被线性地推送（边接收边发送到下一个副本节点）；注意，次要副本节点并不会立即复制数据块，而是在接收到主要副本的写入请求后才进行复制操作；</li>
  <li>主要副本接收并检查版本号和租约后才选择一个偏移量append数据后，告诉次要副本偏移量并开始append，主要副本和次要副本完成写入后（版本号同样持久存储），响应确认，master持久存储版本号）需要吗，主要副本也将更新的版本号返回给client；</li>
  <li>如果有次要副本没有完成写入（即没有响应），主要副本会响应错误给client；</li>
  <li>通常client会发起重试，此时步骤相同，只有偏移量会更新（不会重新利用之前写入的数据部分）；</li>
</ul>

<p><img src="https://acceleratorssr.github.io/image/image.png" alt="请求过程"></p>

<h4>一致性</h4>
<p>The Google File System 

&emsp;&emsp;master维护所有的文件系统元数据。这些元数据包括<strong>命名空间</strong>（namespace）、访问控制信息（access control information）、<strong>文件到块的映射</strong>，以及<strong>块的当前位置</strong>。它还控制整个系统的活动，比如块租约管理（chunk lease management）、孤儿块的垃圾回收，以及chunkserver之间的块迁移。master以心跳（HeartBeat） 消息的方式周期性地和每个chunkserver进行通信，下达指令并收集其状态信息。</p>

<p>&emsp;&emsp;master存储了三种主要类型的元数据: <strong>文件和块命名空间，文件到块的映射，以及每个块的副本的位置</strong>。所有的元数据保存在master的内存中。前两种类型（命名空间和文件到块的映射）也会通过将变更记录到存储在master本地磁盘的<strong>操作日志</strong>（operation log） 而持久化保存，并且被复制到远端机器。使用日志能使我们简单、可靠地更新master的状态，并且如果发生master崩溃（crash）也不会出现不一致的风险。master不会对块位置信息进行持久化存储。取而代之，它会在master启动和chunkserver加入集群时询问每个chunkserver关于该chunkserver上的块（信息）。</p>

<h4>交互流程：</h4>
<ol>
  <li>客户端询问 master 哪个 chunkserver 持有块的当前租约以及其它块的副本位置。如果没有 chunkserver 持有租约，master 会对它选择的一个副本赋予租约（图中没有展示）。</li>
  <li>master 回复 primary 的标识以及其它副本（secondary） 的位置。客户端会为将来的变更缓存这份数据。仅当 primary 不可到达（unreachable）或者 primary 回复其不再持有租约时，客户端才需要再次联系 master。</li>
  <li>客户端把数据推送到所有的副本。客户端可以以任意顺序推送数据。每个 chunkserver 会把数据存储在内部的 LRU buffer 缓存，直到数据被使用或超期（age out）。通过从控制流中将数据流解耦，我们可以根据网络拓扑来调度开销较大的数据流，而不必关心哪个 chunkserver 是 primary，从而改善性能。Section 3.2 对此进行了更深入的讨论。</li>
  <li>一旦所有的副本都确认收到了数据，客户端就会给 primary 发送一个写请求。这个请求标识了之前被推送到所有副本的数据。primary 为其收到的所有变更分配连续的序列号，这些变更可能来自于多个客户端，序列号提供了必要的编序。primary 依据序列号顺序将变更应用到自己的本地状态。</li>
  <li>primary 转发写请求到所有的从副本（secondary replicas），每个从副本以 primary 分配的相同的序列号顺序应用变更。</li>
  <li>所有的从副本对 primary 进行回复以表明它们完成了操作。</li>
  <li>primary 对客户端进行回复。在任何副本上出现的任何错误都会报告给客户端。 在发生错误的情况下，写操作可能已经在 primary 和从副本的某个子集上执行成功（如果它在 primary 上失败，就不会被分配一个序列号和被转发）。这个客户端请求被当作是失败的，且被修改的区域停留在不一致状态。我们的客户端代码通过重试失败的变更来处理这样的错误。它在从写操作开头进行重试之前会在步骤（3）和（7）之间进行几次尝试。</li>
</ol>
