---
layout: post
title: 中文分词库 - Jieba
tags: 调研
excerpt: 利用中文分词词库，通过图结构和动态规划方法找到最大概率词组（阶段一 -使用-）
---

[Jieba 仓库](https://github.com/fxsjy/jieba)
[go 版本](https://github.com/wangbin/jiebago)

# Jieba 介绍

&emsp;&emsp;基于 规则 + 统计；

&emsp;&emsp;通过前缀词典存储尽可能多的词，不仅包含词本身，还包含词前缀；正常情况下输入一个句子，从每个字符开始扫描前缀，找到所有汉字可能成词的组合，构成一个有向无环图（DAG）；

&emsp;&emsp;再通过动态规划查找最大概率路径, 找出基于**词频**（如：TD-IDF，ES 内也有）的最大切分组合；

&emsp;&emsp;对于未登录词，采用了基于汉字成词能力的 HMM 模型，使用了 Viterbi 算法；（人话就是 **基于陌生的词，先获取多种成词的概率，再通过动态规划求解最大概率路径**）（概率包括状态转移、初始状态、发射概率）

> HMM：隐式马尔可夫模型，一种统计模型，描述一个系统在时间序列上的状态变化，由一组隐藏状态和观测集合组成；
> 结构：先定义出一组隐藏状态，如 词首、词中、词尾、单字成词；观测集合是实际的汉字序列，转移概念是从隐藏状态到隐藏状态（如 从词首到词尾）的概率，发射概率是从隐藏状态到观测集合的概率（如 一个汉字在当前隐藏状态下出现的概率）；

> Viterbi 算法：动态规划算法，通过递推求解最优路径，求解最优路径的过程就是动态规划的过程；初始化时，计算第一个观测值对应每个隐藏状态的概率，然后根据后续观测值，利用状态转移概率和发送概率递归计算每个隐藏状态的最大概率路径，最后求解最大概率路径；
